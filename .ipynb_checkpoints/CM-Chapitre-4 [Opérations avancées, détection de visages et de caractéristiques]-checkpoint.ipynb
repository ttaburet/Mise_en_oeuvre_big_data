{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 📕 Trouver les contours avec Canny\n",
    "Dans ce dernier chapitre, nous allons apprendre à détecter les bords, les coins, et les visages des gens ! \n",
    "En utilisant des fonctions de construction qui le font très rapidement et avec seulement quelques lignes de code. \n",
    "La détection des contours est très utilisée lorsque nous voulons diviser l'image en zones correspondant à différents objets.\n",
    "\n",
    "## 📌 Détection des contours\n",
    "Dans le chapitre précédent, nous avons vu comment détecter les bords à l'aide de la technique de filtrage de Sobel. \n",
    "Nous allons maintenant nous familiariser avec l'une des techniques de détection des contours les plus utilisées, la détection des contours de Canny. \n",
    "Cette méthode est largement considérée comme la méthode standard de détection des bords dans le traitement des images. \n",
    "Elle permet de détecter les bords avec une plus grande précision et un temps d'exécution plus court que l'algorithme de Sobel.\n",
    "\n",
    "Le détecteur peut être appliqué avec la fonction Canny du module de caractéristiques de scikit-image. \n",
    "Cette fonction nécessite que l'image soit un tableau à deux dimensions, c'est-à-dire une image en niveaux de gris. \n",
    "Ainsi, dans cet exemple, nous convertissons l'image de RGB-3 en niveaux de gris, en utilisant la méthode rgb2gray du module couleur que nous connaissons déjà dans les chapitres précédents. \n",
    "Ensuite, nous appliquons le détecteur de canny sur l'image de la pièce et nous obtenons l'image résultante.\n",
    "\n",
    "```python\n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "coins = color.rgb2gray(coins)\n",
    "\n",
    "# Appliquer le détecteur de Canny\n",
    "canny_edges = canny(coins)\n",
    "\n",
    "# Afficher l'image résultante avec des bords\n",
    "show_image(canny_edges, \"Bords avec Canny\")\n",
    "```\n",
    "\n",
    "\n",
    "## 📌 Détecteur de bords de Canny\n",
    "La première étape de cet algorithme est d'appliquer un filtre gaussien afin d'éliminer le bruit dans l'image. Le même filtre gaussien que nous avons vu précédemment dans le cours avec la fonction gaussienne du module filtres. \n",
    "Ainsi, dans la fonction canny, vous pouvez éventuellement définir l'intensité de ce filtre gaussien à appliquer dans l'image, en utilisant l'attribut sigma. \n",
    "Plus la valeur de ce sigma est faible, moins l'effet du filtre gaussien est appliqué à l'image, ce qui permet de repérer davantage de bords. \n",
    "D'autre part, si vous définissez une valeur plus élevée, plus de bruit sera supprimé et le résultat sera une image moins tranchante. \n",
    "La valeur par défaut de ce paramètre est 1. Dans cet exemple, nous l'avons fixé à 0.5, voyons l'effet dans l'image.\n",
    "\n",
    "```python\n",
    "# Application d'un Canny avec sigma = 0.5\n",
    "canny_edges_0_5 = canny(coins, sigma=0.5)\n",
    "\n",
    "# Affichage des images avec contours\n",
    "show_image(canny_edges, \"Sigma = 1\")\n",
    "show_image(canny_edges_0_5, \"Sigma = 0.5\")\n",
    "```\n",
    "\n",
    "En utilisant ceci, l'image résultante aura beaucoup plus de bords que la précédente et ceci parce que le bruit a été supprimé avant de continuer avec le reste des étapes de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "def show_image(image, title='Image', cmap_type='gray'):\n",
    "    plt.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def plot_comparison(img_original, img_filtered, img_title_filtered):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    ax1.imshow(img_original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('Originale')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(img_filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(img_title_filtered)\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## 📝 Contours\n",
    "Dans cet exercice, vous allez identifier les formes dans une image de pamplemousse en détectant les bords, en utilisant l'algorithme de Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "from skimage import color\n",
    "\n",
    "grapefruit = imread('data/CM_SampleImages/Chapter4/toronjas.png')\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruitb = color.rgb2gray(color.rgba2rgb(grapefruit))\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruitb)\n",
    "\n",
    "# Show resulting image\n",
    "plot_comparison(grapefruit, canny_edges, \"Contours obtenus avec Canny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝Less \"edgy\"\n",
    "\n",
    "Essayons maintenant de repérer uniquement la forme extérieure des pamplemousses, les cercles. Vous pouvez le faire en appliquant un filtre gaussien plus intense pour rendre l'image plus lisse. Cela peut être réalisé en spécifiant un sigma plus grand dans la fonction canny.\n",
    "\n",
    "Dans cet exercice, vous allez expérimenter les valeurs sigma de la fonction <code>canny()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_1_8 = canny(grapefruitb, sigma=1.8)\n",
    "\n",
    "# Canny avec sigma of 2.2\n",
    "edges_2_2 = canny(grapefruitb, sigma=2.2)\n",
    "\n",
    "# Affichage des résultats\n",
    "plot_comparison(edges_1_8, edges_2_2, 'Changement de sigma de 1.8 à 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# 📕 Détection des coins\n",
    "La détection des coins est une approche utilisée pour extraire certains types de caractéristiques et déduire le contenu d'une image. \n",
    "Elle est fréquemment utilisée dans la détection de mouvements, le recalage d'images, le suivi vidéo, l'assemblage de panoramas, la modélisation 3D et la reconnaissance d'objets. \n",
    "Nous avons vu dans la vidéo précédente comment détecter les bords avec le détecteur de bords de Canny, et avant cela avec Sobel, dans le chapitre 2. \n",
    "Les contours sont un type de caractéristique dans les images.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/corners.png\" width=\"60%\" center/>\n",
    "\n",
    "## 📌 Points d'intérêt\n",
    "Les caractéristiques sont les points d'intérêt qui fournissent des informations riches sur le contenu de l'image. \n",
    "Les points d'intérêt sont des points dans l'image qui sont invariants par rapport aux changements de rotation, de translation, d'intensité et d'échelle. (Fondamentalement, ils sont robustes et fiables). \n",
    "Il existe différents points d'intérêt tels que les coins et les bords. \n",
    "Ainsi, la détection des coins consiste essentiellement à détecter (un type de) points d'intérêt dans une image.\n",
    "\n",
    "## 📌 Coins\n",
    "Un coin peut être défini comme l'intersection de deux arêtes. Intuitivement, il peut également s'agir d'une jonction de contours.\n",
    "\n",
    "## 📌 Correspondance des coins\n",
    "En détectant les coins comme des points d'intérêt, nous pouvons faire correspondre des objets de différentes perspectives. \n",
    "Comme dans cette image, où nous détectons les coins de l'image originale à gauche et les faisons correspondre dans une image réduite à droite.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/originalVsTransformed.png\" width=\"600\" center/>\n",
    "\n",
    "## 📌 Détecteur de coins de Harris\n",
    "Le détecteur de coins de Harris est un opérateur de détection de coins qui est largement utilisé dans les algorithmes de vision par ordinateur. \n",
    "Ici, nous voyons l'image originale d'un bâtiment, et à droite, nous voyons les coins détectés par l'algorithme de Harris, marqués en rouge.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/cornersD.png\" width=\"60%\" center/>\n",
    "\n",
    "Nous pouvons y accéder en important la fonction corner_harris du module feature de scikit-image. \n",
    "Cette fonction nécessite des images en niveaux de gris, nous devons donc d'abord convertir l'image de rgb en gris. \n",
    "Nous pouvons le faire avec la fonction rgb2gray que nous avons utilisée précédemment. \n",
    "Cette fonction corner_harris nous donne l'image de la mesure de Harris, c'est-à-dire l'image résultante montrant seulement les coins possibles qui ont été mesurés. \n",
    "\n",
    "```python\n",
    "from skimage.feature import corner_harris\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "image = rgb2gray(image)\n",
    "\n",
    "# Appliquer le détecteur de coins de Harris sur l'image\n",
    "measure_image = corner_harris(image)\n",
    "\n",
    "# Afficher l'image de la réponse de Harris\n",
    "show_image(measure_image)\n",
    "```\n",
    "<br/>\n",
    "<img src=\"data/CM_SampleImages/Chapter4/harrisResponse.png\" width=\"60%\" center/>\n",
    "\n",
    "Nous voyons que seules quelques lignes noires sont représentées. \n",
    "Ce sont les points approximatifs où se trouvent les coins candidats.\n",
    "\n",
    "Pour trouver les coins dans l'image de la réponse à la mesure, nous pouvons utiliser la fonction corner_peaks.\n",
    "Celle-ci renvoie les coordonnées des pics des coins possibles. \n",
    "En option, nous pouvons nous assurer que ces sommets sont séparés par une distance minimale, en pixels, en utilisant le paramètre min_distance. \n",
    "Ici, nous fixons la distance minimale entre les coins à 5 pixels. \n",
    "Dans cette image, un total de 122 coins a été trouvé à partir de l'image de la réponse à la mesure.\n",
    "\n",
    "```python\n",
    "# Recherche des coordonnées des coins\n",
    "coords = corner_peaks(corner_harris(image), min_distance=5)\n",
    "\n",
    "print(\"Un total de\", len(coords), \"coins ont été trouvés.\")\n",
    "```\n",
    "\n",
    "<code>Un total de 122 coins ont été trouvés.</code>\n",
    "\n",
    "## 📌 Corners detected\n",
    "```python\n",
    "# Afficher l'image avec des marques aux endroits identifiés\n",
    "show_image_with_detected_corners(image, coords)\n",
    "```\n",
    "<img src=\"data/CM_SampleImages/Chapter4/corners_detected.png\" width=\"60%\" center/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝Perspective\n",
    "n this exercise, you will detect the corners of a building using the Harris corner detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_corners(image, coords, title=\"coins détectés\"):\n",
    "    plt.imshow(image, interpolation='nearest', cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.plot(coords[:, 1], coords[:, 0], '+r', markersize=15)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "building_image = imread('data/CM_SampleImages/Chapter4/corners_building_top.jpg')\n",
    "\n",
    "# Convertir l'image de RGB en échelle de gris.\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "# Appliquer le détecteur pour mesurer les coins possibles\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Trouver les pics des coins en utilisant le détecteur de Harris\n",
    "coords = corner_peaks(measure_image, min_distance=2, threshold_rel=0)\n",
    "\n",
    "# Montrer l'image originale et l'image résultante avec les coins détectés\n",
    "show_image(building_image, 'Originale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝 Moins de coins\n",
    "Dans cet exercice, vous allez tester ce qui se passe lorsque vous fixez la distance minimale entre les sommets des coins à un nombre plus élevé. Rappelez-vous que vous faites cela avec le paramètre d'attribut min_distance de la fonction corner_peaks()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_w_min_2 = corner_peaks(measure_image, min_distance=2, threshold_rel=0)\n",
    "print(\"Avec une distance minimale fixée à {}, nous détectons un total de {} coins dans l'image.\".format(2, len(coords_w_min_2)))\n",
    "# Find the peaks with a min distance of 40 pixels\n",
    "coords_w_min_40 = corner_peaks(measure_image, min_distance=40, threshold_rel=0)\n",
    "print(\"Avec une distance minimale fixée à {}, nous détectons un total de {} coins dans l'image.\".format(40, len(coords_w_min_40)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords_w_min_2, \"Coins détectés avec 2px de distance minimale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords_w_min_40, \"Coins détectés avec 40px de distance minimale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# 📕 Détection des visages\n",
    "Au cours des dernières années, la détection des visages a attiré beaucoup d'attention et a eu un grand impact sur les processus automatisés grâce à la vision artificielle. \n",
    "\n",
    "## 📌 Cas d'utilisation de la détection des visages\n",
    "- Filtres\n",
    "- Mise au point automatique\n",
    "- Recommandations\n",
    "- Flou pour la protection de la vie privée\n",
    "- Reconnaître les émotions\n",
    "\n",
    "## 📌 Détection de visages avec scikit-image\n",
    "Avec scikit-image, nous pouvons détecter les visages à l'aide d'un classificateur d'apprentissage automatique, en quelques lignes seulement ! \n",
    "Dans ce cours, nous ne couvrirons pas les concepts d'apprentissage automatique en profondeur, mais il est important de savoir que nous utilisons une cascade de classificateurs, qui est comme plusieurs classificateurs en un. \n",
    "Vous pouvez également l'utiliser pour d'autres choses, comme des chats, des objets ou des visages de profil, en vue de côté.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/face_detection.png\" width=\"70%\" center/>\n",
    "\n",
    "Pour utiliser le détecteur de visage, nous importons la classe Cascade du module de fonctionnalité. \n",
    "Ce framework de détection a besoin d'un fichier xml, à partir duquel les données entraînées peuvent être lues.\n",
    "Dans ce cas, nous utiliserons les fichiers de visages frontaux qui sont inclus dans le module de données de scikit-image. \n",
    "Ensuite, initialiser le détecteur, en utilisant le constructeur de la classe Cascade. \n",
    "Maintenant, nous avons maintenant le détecteur prêt à être utilisé sur des images.\n",
    "\n",
    "```python\n",
    "# Importation de la classe du classifier\n",
    "from skimage.feature import Cascade\n",
    "\n",
    "# Chargement du fichier de train à partir du module 'root'\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialisation du detecteur Cascade\n",
    "detector = Cascade(trained_file)\n",
    "```\n",
    "\n",
    "## 📌 Détection des visages\n",
    "Pour appliquer le détecteur sur des images, nous devons utiliser la méthode detect_multi_scale, de la même classe cascade. \n",
    "Cette méthode recherche l'objet, dans ce cas un visage. \n",
    "Elle crée une fenêtre qui va se déplacer dans l'image jusqu'à ce qu'elle trouve quelque chose qui ressemble à un visage humain.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/ins.png\" width=\"400\" center/>\n",
    "\n",
    "La recherche se fait à plusieurs échelles. La fenêtre aura une taille minimale, pour repérer les visages petits ou éloignés. \n",
    "Et une taille maximale pour trouver également les plus grands visages dans l'image.\n",
    "Cette méthode prend donc l' **image d'entrée** comme premier paramètre, un **facteur d'échelle**, par lequel la fenêtre de recherche est multipliée à chaque étape, un **rapport d'étape**, dans lequel 1 représente une recherche exhaustive et est généralement lent. \n",
    "En fixant ce paramètre à des valeurs plus élevées, les résultats seront moins bons mais le calcul sera beaucoup plus rapide. \n",
    "Habituellement, des valeurs comprises entre 1 et 1,5 donnent de bons résultats. \n",
    "Ensuite, les **taille minimale et maximale de la fenêtre** sont définies. \n",
    "Elles spécifient l'intervalle des fenêtres de recherche qui sont appliquées à l'image d'entrée pour détecter les visages.\n",
    "\n",
    "```python\n",
    "detected = detector.detect_multi_scale(img=image, \n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "```\n",
    "\n",
    "## 📌 Visages détectés  \n",
    "\n",
    "```python\n",
    "print(detected)\n",
    "# Affichage de l'image avec le visage détecté identifié\n",
    "show_detected_face(image, detected)\n",
    "```\n",
    "<code>Detected face: [{'r': 115, 'c': 210, 'width': 167, 'height': 167}]</code>\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/ins_detect.png\" width=\"400\" center/>\n",
    "\n",
    "#### Affichage des visages détectés\n",
    "Avec cette fonction, on trace un rectangle autour des faces détectées. \n",
    "Nous ne discuterons pas de cette fonction en détail ici.\n",
    "\n",
    "```python\n",
    "def show_detected_face(result, detected, title=\"Image du visage\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for patch in detected:\n",
    "        \n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2)\n",
    "        )\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝Il y a quelqu'un ?\n",
    "Dans cet exercice, vous allez vérifier si une personne est présente ou non dans une image prise la nuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def crop_face(result, detected, title=\"Visage détecté\"):\n",
    "    for d in detected:\n",
    "        print(d)\n",
    "        rostro= result[d['r']:d['r']+d['width'], d['c']:d['c']+d['height']]\n",
    "    \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(rostro)    \n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def show_detected_face(result, detected, title=\"Image du visage\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for patch in detected:\n",
    "        \n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2)\n",
    "        )\n",
    "    plt.show()\n",
    "    crop_face(result, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.feature import Cascade\n",
    "\n",
    "night_image = imread('data/CM_SampleImages/Chapter4/face_det3.jpg')\n",
    "\n",
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img=night_image, scale_factor=1.2,\n",
    "                                       step_ratio=1, min_size=(10, 10), max_size=(200, 200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝Visages multiples\n",
    "Dans cet exercice, vous allez détecter plusieurs visages dans une image et les afficher individuellement.\n",
    "Pensez-y comme un moyen de créer un ensemble de données sur les visages de vos propres amis !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_image = imread('data/CM_SampleImages/Chapter4/face_det_friends.jpg')\n",
    "\n",
    "# Détecter les visages avec un facteur d'échelle de 1.2 et un rapport d'étape de 1.\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "\n",
    "# Afficher les visages détectés\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝Segmentation et détection de visage\n",
    "Auparavant, vous avez appris à rendre les processus plus efficaces en termes de calcul avec une segmentation superpixel non supervisée. Dans cet exercice, c'est exactement ce que vous ferez !\n",
    "\n",
    "À l'aide de la fonction <code>slic()</code> pour la segmentation, réaliser le pré-traitement de l'image avant de la transmettre au détecteur de visage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "profile_image = imread('data/CM_SampleImages/Chapter4/face_det.jpg')\n",
    "\n",
    "# Obtention de la segmentation avec 100 régions par défaut\n",
    "segments = slic(profile_image, start_label=1)\n",
    "\n",
    "# Obtention de l'image segmentée en utilisant label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg', bg_label=0)\n",
    "\n",
    "# Détection des visages avec la méthode multi-échelle\n",
    "detected = detector.detect_multi_scale(img=segmented_image, scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(1000, 1000))\n",
    "\n",
    "# Affichage des visages détectés\n",
    "show_detected_face(segmented_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# 📕Applications dans le monde réel\n",
    "Nous allons maintenant apprendre à appliquer ce que nous avons appris dans des situations du \"real-world\". Pour ce faire, nous allons combiner des techniques.\n",
    "\n",
    "## 📌 Applications\n",
    "- Passage en niveaux de gris avant la détection des bords/coins\n",
    "- Réduction du bruit et restauration des images\n",
    "- Détection de visages flous\n",
    "- Approximation de la taille des objets\n",
    "\n",
    "## 📌 Protection de la vie privée\n",
    "Voyons comment résoudre un cas de protection de la vie privée en détectant les visages, puis en les rendant anonymes. Nous allons utiliser cette image pour travailler.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/friends.png\" width=\"450\" center/>\n",
    "\n",
    "Donc, pour ce cas en particulier, nous devrons d'abord détecter les visages, en utilisant le détecteur de cascade de classificateurs, puis appliquer un filtre gaussien aux visages recadrés.\n",
    "```python\n",
    "# Importation du détecteur de cascade de classifieurs et un filtre gaussien\n",
    "from skimage.feature import Cascade\n",
    "from skimage.filters import gaussian\n",
    "```\n",
    "<br/>\n",
    "Ainsi, avec le détecteur de visage initialisé et prêt à l'emploi, nous pouvons commencer à détecter les visages. Pour chaque visage détecté, comme la variable d, dans la liste détectée, nous allons utiliser les coordonnées pour le recadrer de l'image, c'est-à-dire l'extraire.\n",
    "\n",
    "```python\n",
    "# Détection des visages\n",
    "detected = detector.detect_multi_scale(img=image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(50, 50),\n",
    "                                       max_size=(100, 100))\n",
    "# Pour chaque visage détecté\n",
    "for d in detected:\n",
    "    # Obtention du visage recadré à partir des coordonnées détectées\n",
    "    face = getFace(d)\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Cette fonction <code>getFace()</code> découpe le visage de l'image, en utilisant le dictionnaire des visages détectés qui contient les coordonnées. \n",
    "Ensuite, nous allons dessiner un rectangle autour du visage détecté de l'image. \n",
    "En prenant r, qui est la position de la ligne du coin supérieur gauche du rectangle détecté comme position de départ X et c, qui est la colonne comme position de départ Y.\n",
    "\n",
    "```python\n",
    "def getFace(d):\n",
    "    # Extraction du rectangle du visage de l'image en utilisant les coordonnées du visage détecté.\n",
    "   \n",
    "    # X et Y points de départ du rectangle du visage\n",
    "    x, y = d['r'], d['c']\n",
    "    \n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "    \n",
    "    # Extraction du visage détecté\n",
    "    face= image[x:width, y:height]\n",
    "    \n",
    "    return face\n",
    "```\n",
    "\n",
    "Ce sont les points à partir desquels nous allons maintenant ajouter une largeur et une hauteur pour compléter le rectangle. Et c'est exactement ce que nous faisons ensuite, nous ajoutons la hauteur et la largeur aux points de départ. Nous avons donc les dimensions du rectangle dans l'image. Nous spécifions ensuite ces dimensions dans l'image d'origine à partir de laquelle le visage a été détecté afin de pouvoir le recadrer.\n",
    "\n",
    "<br/>\n",
    "Maintenant que le visage est recadré de l'image, nous allons appliquer le filtre gaussien pour le rendre flou et le rendre méconnaissable. Cette\n",
    "l'image résultante est affectée à la variable gaussian_face.\n",
    "\n",
    "```python\n",
    "# Détection des visages\n",
    "detected = detector.detect_multi_scale(img=image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(50, 50),\n",
    "                                       max_size=(100, 100))\n",
    "# Pour chaque visage détecté\n",
    "for d in detected:\n",
    "    # Obtention du visage isolé à partir des coordonnées obtenues\n",
    "    face = getFace(d)\n",
    "    \n",
    "    # Application d'un filtre gaussien sur les visages obtenus\n",
    "    gaussian_face = gaussian(face, multichannel=True, sigma = 10)\n",
    "    \n",
    "    # Fusion de ce visage flou avec notre image finale et affichage final\n",
    "    resulting_image = mergeBlurryFace(image, gaussian_face)\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Comme dernière étape, nous allons fusionner le visage flou à nouveau à l'image, en utilisant une autre fonction appelée <code>mergeBlurryFace()</code> Pour ce faire, nous spécifions à nouveau les points de départ X et Y ainsi que la largeur et la hauteur, afin de découper l'image originale. Ensuite, le visage flou est affecté au résultat.\n",
    "\n",
    "```python\n",
    "def mergeBlurryFace(original, gaussian_image):\n",
    "    # Les points de départ X et Y du rectangle du visage.\n",
    "    x, y = d['r'], d['c'] \n",
    "    # La largeur et la hauteur du rectangle de la face\n",
    "    width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "    \n",
    "    original[ x:width, y:height] = gaussian_image\n",
    "    return original\n",
    "```\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/blurr_faces.png\" width=\"450\" center/>\n",
    "\n",
    "Il en résulte donc une image qui ne contient plus les visages des personnes et, de cette manière, les données personnelles sont anonymisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  📝 Protection de la vie privée\n",
    "Prenons une application réelle de ce que vous avez appris dans ce cours.\n",
    "\n",
    "Dans cet exercice, vous allez détecter des visages humains dans l'image et, au nom de la protection de la vie privée, vous allez anonymiser les données en floutant automatiquement les visages des personnes dans l'image.\n",
    "\n",
    "Vous pouvez utiliser le filtre gaussien pour le flou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceRectangle(image, d):\n",
    "    ''' Extraction du visage à partir de l'image en utilisant les coordonnées de l'image détectée. '''\n",
    "    # Points de départ X et Y du rectangle de la face\n",
    "    x, y  = d['r'], d['c']\n",
    "    \n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']\n",
    "    \n",
    "    # Extraction du visage détecté\n",
    "    face= image[ x:width, y:height]\n",
    "    return face\n",
    "\n",
    "def mergeBlurryFace(original, gaussian_image):\n",
    "     # Points de départ X et Y du rectangle du visage\n",
    "    x, y  = d['r'], d['c']\n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']\n",
    "    \n",
    "    original[ x:width, y:height] = gaussian_image\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "group_image = imread('data/CM_SampleImages/Chapter4/face_det25.jpg')\n",
    "\n",
    "# Détection des visages\n",
    "detected = detector.detect_multi_scale(img=group_image, scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10), max_size=(100, 100))\n",
    "\n",
    "# Pour chaque visage détecté\n",
    "for d in detected:\n",
    "    # Obtention du rectangle du visage à partir des coordonnées détectées\n",
    "    face = getFaceRectangle(group_image, d)\n",
    "    \n",
    "    # Application du filtre gaussien au visage extrait\n",
    "    blurred_face = gaussian(face, channel_axis=-1, sigma=8, preserve_range=True)\n",
    "    \n",
    "    # Fusion de ce visage flou à notre image finale et affichage\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face)\n",
    "    \n",
    "show_image(resulting_image, 'Blurred faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "##  📝 Aidez Sally à restaurer sa photo de fin d'études\n",
    "Vous allez combiner toutes les connaissances que vous avez acquises tout au long du cours pour relever un dernier défi : reconstruire une photo très endommagée.\n",
    "\n",
    "Aidez Sally à restaurer son portrait préféré qui a été endommagé par du bruit, de la distorsion et des informations manquantes en raison d'une brèche dans son ordinateur portable.\n",
    "\n",
    "Vous allez résoudre les problèmes de cette image en :\n",
    "\n",
    "- La faisant pivoter pour qu'elle soit droite en utilisant rotate()\n",
    "- Appliquant une réduction du bruit avec denoise_tv_chambolle()\n",
    "- Reconstruisant les parties endommagées avec inpaint_biharmonic() du module inpaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(image):\n",
    "    # Création d'un masque avec trois régions de défauts : gauche, milieu, droite respectivement.\n",
    "    mask_for_solution = np.zeros(image.shape[:-1])\n",
    "    mask_for_solution[450:475, 470:495] = 1\n",
    "    mask_for_solution[320:355, 140:175] = 1\n",
    "    mask_for_solution[130:155, 345:370] = 1\n",
    "    return mask_for_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "damaged_image = imread('data/CM_SampleImages/Chapter4/sally_damaged_image.jpg')\n",
    "\n",
    "# Transformation de l'image pour qu'elle ne soit pas en rotation\n",
    "upright_img = transform.rotate(damaged_image, 20)\n",
    "\n",
    "# Élimination du bruit de l'image, en utilisant la méthode de Chambolle\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img, weight=0.1, channel_axis=-1)\n",
    "\n",
    "# Reconstruction des parties manquantes de l'image\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, channel_axis=-1)\n",
    "\n",
    "# Affichage de l'image résultante\n",
    "plot_comparison(damaged_image, result, \"Reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
