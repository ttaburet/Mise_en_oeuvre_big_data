{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üìï Trouver les contours avec Canny\n",
    "Dans ce dernier chapitre, nous allons apprendre √† d√©tecter les bords, les coins, et les visages des gens ! \n",
    "En utilisant des fonctions de construction qui le font tr√®s rapidement et avec seulement quelques lignes de code. \n",
    "La d√©tection des contours est tr√®s utilis√©e lorsque nous voulons diviser l'image en zones correspondant √† diff√©rents objets.\n",
    "\n",
    "## üìå D√©tection des contours\n",
    "Dans le chapitre pr√©c√©dent, nous avons vu comment d√©tecter les bords √† l'aide de la technique de filtrage de Sobel. \n",
    "Nous allons maintenant nous familiariser avec l'une des techniques de d√©tection des contours les plus utilis√©es, la d√©tection des contours de Canny. \n",
    "Cette m√©thode est largement consid√©r√©e comme la m√©thode standard de d√©tection des bords dans le traitement des images. \n",
    "Elle permet de d√©tecter les bords avec une plus grande pr√©cision et un temps d'ex√©cution plus court que l'algorithme de Sobel.\n",
    "\n",
    "Le d√©tecteur peut √™tre appliqu√© avec la fonction Canny du module de caract√©ristiques de scikit-image. \n",
    "Cette fonction n√©cessite que l'image soit un tableau √† deux dimensions, c'est-√†-dire une image en niveaux de gris. \n",
    "Ainsi, dans cet exemple, nous convertissons l'image de RGB-3 en niveaux de gris, en utilisant la m√©thode rgb2gray du module couleur que nous connaissons d√©j√† dans les chapitres pr√©c√©dents. \n",
    "Ensuite, nous appliquons le d√©tecteur de canny sur l'image de la pi√®ce et nous obtenons l'image r√©sultante.\n",
    "\n",
    "```python\n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "coins = color.rgb2gray(coins)\n",
    "\n",
    "# Appliquer le d√©tecteur de Canny\n",
    "canny_edges = canny(coins)\n",
    "\n",
    "# Afficher l'image r√©sultante avec des bords\n",
    "show_image(canny_edges, \"Bords avec Canny\")\n",
    "```\n",
    "\n",
    "\n",
    "## üìå D√©tecteur de bords de Canny\n",
    "La premi√®re √©tape de cet algorithme est d'appliquer un filtre gaussien afin d'√©liminer le bruit dans l'image. Le m√™me filtre gaussien que nous avons vu pr√©c√©demment dans le cours avec la fonction gaussienne du module filtres. \n",
    "Ainsi, dans la fonction canny, vous pouvez √©ventuellement d√©finir l'intensit√© de ce filtre gaussien √† appliquer dans l'image, en utilisant l'attribut sigma. \n",
    "Plus la valeur de ce sigma est faible, moins l'effet du filtre gaussien est appliqu√© √† l'image, ce qui permet de rep√©rer davantage de bords. \n",
    "D'autre part, si vous d√©finissez une valeur plus √©lev√©e, plus de bruit sera supprim√© et le r√©sultat sera une image moins tranchante. \n",
    "La valeur par d√©faut de ce param√®tre est 1. Dans cet exemple, nous l'avons fix√© √† 0.5, voyons l'effet dans l'image.\n",
    "\n",
    "```python\n",
    "# Application d'un Canny avec sigma = 0.5\n",
    "canny_edges_0_5 = canny(coins, sigma=0.5)\n",
    "\n",
    "# Affichage des images avec contours\n",
    "show_image(canny_edges, \"Sigma = 1\")\n",
    "show_image(canny_edges_0_5, \"Sigma = 0.5\")\n",
    "```\n",
    "\n",
    "En utilisant ceci, l'image r√©sultante aura beaucoup plus de bords que la pr√©c√©dente et ceci parce que le bruit a √©t√© supprim√© avant de continuer avec le reste des √©tapes de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "def show_image(image, title='Image', cmap_type='gray'):\n",
    "    plt.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def plot_comparison(img_original, img_filtered, img_title_filtered):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    ax1.imshow(img_original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('Originale')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(img_filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(img_title_filtered)\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## üìù Contours\n",
    "Dans cet exercice, vous allez identifier les formes dans une image de pamplemousse en d√©tectant les bords, en utilisant l'algorithme de Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "from skimage import color\n",
    "\n",
    "grapefruit = imread('data/CM_SampleImages/Chapter4/toronjas.png')\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruitb = color.rgb2gray(color.rgba2rgb(grapefruit))\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruitb)\n",
    "\n",
    "# Show resulting image\n",
    "plot_comparison(grapefruit, canny_edges, \"Contours obtenus avec Canny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìùLess \"edgy\"\n",
    "\n",
    "Essayons maintenant de rep√©rer uniquement la forme ext√©rieure des pamplemousses, les cercles. Vous pouvez le faire en appliquant un filtre gaussien plus intense pour rendre l'image plus lisse. Cela peut √™tre r√©alis√© en sp√©cifiant un sigma plus grand dans la fonction canny.\n",
    "\n",
    "Dans cet exercice, vous allez exp√©rimenter les valeurs sigma de la fonction <code>canny()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_1_8 = canny(grapefruitb, sigma=1.8)\n",
    "\n",
    "# Canny avec sigma of 2.2\n",
    "edges_2_2 = canny(grapefruitb, sigma=2.2)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "plot_comparison(edges_1_8, edges_2_2, 'Changement de sigma de 1.8 √† 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# üìï D√©tection des coins\n",
    "La d√©tection des coins est une approche utilis√©e pour extraire certains types de caract√©ristiques et d√©duire le contenu d'une image. \n",
    "Elle est fr√©quemment utilis√©e dans la d√©tection de mouvements, le recalage d'images, le suivi vid√©o, l'assemblage de panoramas, la mod√©lisation 3D et la reconnaissance d'objets. \n",
    "Nous avons vu dans la vid√©o pr√©c√©dente comment d√©tecter les bords avec le d√©tecteur de bords de Canny, et avant cela avec Sobel, dans le chapitre 2. \n",
    "Les contours sont un type de caract√©ristique dans les images.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/corners.png\" width=\"60%\" center/>\n",
    "\n",
    "## üìå Points d'int√©r√™t\n",
    "Les caract√©ristiques sont les points d'int√©r√™t qui fournissent des informations riches sur le contenu de l'image. \n",
    "Les points d'int√©r√™t sont des points dans l'image qui sont invariants par rapport aux changements de rotation, de translation, d'intensit√© et d'√©chelle. (Fondamentalement, ils sont robustes et fiables). \n",
    "Il existe diff√©rents points d'int√©r√™t tels que les coins et les bords. \n",
    "Ainsi, la d√©tection des coins consiste essentiellement √† d√©tecter (un type de) points d'int√©r√™t dans une image.\n",
    "\n",
    "## üìå Coins\n",
    "Un coin peut √™tre d√©fini comme l'intersection de deux ar√™tes. Intuitivement, il peut √©galement s'agir d'une jonction de contours.\n",
    "\n",
    "## üìå Correspondance des coins\n",
    "En d√©tectant les coins comme des points d'int√©r√™t, nous pouvons faire correspondre des objets de diff√©rentes perspectives. \n",
    "Comme dans cette image, o√π nous d√©tectons les coins de l'image originale √† gauche et les faisons correspondre dans une image r√©duite √† droite.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/originalVsTransformed.png\" width=\"600\" center/>\n",
    "\n",
    "## üìå D√©tecteur de coins de Harris\n",
    "Le d√©tecteur de coins de Harris est un op√©rateur de d√©tection de coins qui est largement utilis√© dans les algorithmes de vision par ordinateur. \n",
    "Ici, nous voyons l'image originale d'un b√¢timent, et √† droite, nous voyons les coins d√©tect√©s par l'algorithme de Harris, marqu√©s en rouge.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/cornersD.png\" width=\"60%\" center/>\n",
    "\n",
    "Nous pouvons y acc√©der en important la fonction corner_harris du module feature de scikit-image. \n",
    "Cette fonction n√©cessite des images en niveaux de gris, nous devons donc d'abord convertir l'image de rgb en gris. \n",
    "Nous pouvons le faire avec la fonction rgb2gray que nous avons utilis√©e pr√©c√©demment. \n",
    "Cette fonction corner_harris nous donne l'image de la mesure de Harris, c'est-√†-dire l'image r√©sultante montrant seulement les coins possibles qui ont √©t√© mesur√©s. \n",
    "\n",
    "```python\n",
    "from skimage.feature import corner_harris\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "image = rgb2gray(image)\n",
    "\n",
    "# Appliquer le d√©tecteur de coins de Harris sur l'image\n",
    "measure_image = corner_harris(image)\n",
    "\n",
    "# Afficher l'image de la r√©ponse de Harris\n",
    "show_image(measure_image)\n",
    "```\n",
    "<br/>\n",
    "<img src=\"data/CM_SampleImages/Chapter4/harrisResponse.png\" width=\"60%\" center/>\n",
    "\n",
    "Nous voyons que seules quelques lignes noires sont repr√©sent√©es. \n",
    "Ce sont les points approximatifs o√π se trouvent les coins candidats.\n",
    "\n",
    "Pour trouver les coins dans l'image de la r√©ponse √† la mesure, nous pouvons utiliser la fonction corner_peaks.\n",
    "Celle-ci renvoie les coordonn√©es des pics des coins possibles. \n",
    "En option, nous pouvons nous assurer que ces sommets sont s√©par√©s par une distance minimale, en pixels, en utilisant le param√®tre min_distance. \n",
    "Ici, nous fixons la distance minimale entre les coins √† 5 pixels. \n",
    "Dans cette image, un total de 122 coins a √©t√© trouv√© √† partir de l'image de la r√©ponse √† la mesure.\n",
    "\n",
    "```python\n",
    "# Recherche des coordonn√©es des coins\n",
    "coords = corner_peaks(corner_harris(image), min_distance=5)\n",
    "\n",
    "print(\"Un total de\", len(coords), \"coins ont √©t√© trouv√©s.\")\n",
    "```\n",
    "\n",
    "<code>Un total de 122 coins ont √©t√© trouv√©s.</code>\n",
    "\n",
    "## üìå Corners detected\n",
    "```python\n",
    "# Afficher l'image avec des marques aux endroits identifi√©s\n",
    "show_image_with_detected_corners(image, coords)\n",
    "```\n",
    "<img src=\"data/CM_SampleImages/Chapter4/corners_detected.png\" width=\"60%\" center/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìùPerspective\n",
    "n this exercise, you will detect the corners of a building using the Harris corner detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_corners(image, coords, title=\"coins d√©tect√©s\"):\n",
    "    plt.imshow(image, interpolation='nearest', cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.plot(coords[:, 1], coords[:, 0], '+r', markersize=15)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "building_image = imread('data/CM_SampleImages/Chapter4/corners_building_top.jpg')\n",
    "\n",
    "# Convertir l'image de RGB en √©chelle de gris.\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "# Appliquer le d√©tecteur pour mesurer les coins possibles\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Trouver les pics des coins en utilisant le d√©tecteur de Harris\n",
    "coords = corner_peaks(measure_image, min_distance=2, threshold_rel=0)\n",
    "\n",
    "# Montrer l'image originale et l'image r√©sultante avec les coins d√©tect√©s\n",
    "show_image(building_image, 'Originale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìù Moins de coins\n",
    "Dans cet exercice, vous allez tester ce qui se passe lorsque vous fixez la distance minimale entre les sommets des coins √† un nombre plus √©lev√©. Rappelez-vous que vous faites cela avec le param√®tre d'attribut min_distance de la fonction corner_peaks()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_w_min_2 = corner_peaks(measure_image, min_distance=2, threshold_rel=0)\n",
    "print(\"Avec une distance minimale fix√©e √† {}, nous d√©tectons un total de {} coins dans l'image.\".format(2, len(coords_w_min_2)))\n",
    "# Find the peaks with a min distance of 40 pixels\n",
    "coords_w_min_40 = corner_peaks(measure_image, min_distance=40, threshold_rel=0)\n",
    "print(\"Avec une distance minimale fix√©e √† {}, nous d√©tectons un total de {} coins dans l'image.\".format(40, len(coords_w_min_40)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords_w_min_2, \"Coins d√©tect√©s avec 2px de distance minimale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_with_corners(building_image, coords_w_min_40, \"Coins d√©tect√©s avec 40px de distance minimale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# üìï D√©tection des visages\n",
    "Au cours des derni√®res ann√©es, la d√©tection des visages a attir√© beaucoup d'attention et a eu un grand impact sur les processus automatis√©s gr√¢ce √† la vision artificielle. \n",
    "\n",
    "## üìå Cas d'utilisation de la d√©tection des visages\n",
    "- Filtres\n",
    "- Mise au point automatique\n",
    "- Recommandations\n",
    "- Flou pour la protection de la vie priv√©e\n",
    "- Reconna√Ætre les √©motions\n",
    "\n",
    "## üìå D√©tection de visages avec scikit-image\n",
    "Avec scikit-image, nous pouvons d√©tecter les visages √† l'aide d'un classificateur d'apprentissage automatique, en quelques lignes seulement ! \n",
    "Dans ce cours, nous ne couvrirons pas les concepts d'apprentissage automatique en profondeur, mais il est important de savoir que nous utilisons une cascade de classificateurs, qui est comme plusieurs classificateurs en un. \n",
    "Vous pouvez √©galement l'utiliser pour d'autres choses, comme des chats, des objets ou des visages de profil, en vue de c√¥t√©.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/face_detection.png\" width=\"70%\" center/>\n",
    "\n",
    "Pour utiliser le d√©tecteur de visage, nous importons la classe Cascade du module de fonctionnalit√©. \n",
    "Ce framework de d√©tection a besoin d'un fichier xml, √† partir duquel les donn√©es entra√Æn√©es peuvent √™tre lues.\n",
    "Dans ce cas, nous utiliserons les fichiers de visages frontaux qui sont inclus dans le module de donn√©es de scikit-image. \n",
    "Ensuite, initialiser le d√©tecteur, en utilisant le constructeur de la classe Cascade. \n",
    "Maintenant, nous avons maintenant le d√©tecteur pr√™t √† √™tre utilis√© sur des images.\n",
    "\n",
    "```python\n",
    "# Importation de la classe du classifier\n",
    "from skimage.feature import Cascade\n",
    "\n",
    "# Chargement du fichier de train √† partir du module 'root'\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialisation du detecteur Cascade\n",
    "detector = Cascade(trained_file)\n",
    "```\n",
    "\n",
    "## üìå D√©tection des visages\n",
    "Pour appliquer le d√©tecteur sur des images, nous devons utiliser la m√©thode detect_multi_scale, de la m√™me classe cascade. \n",
    "Cette m√©thode recherche l'objet, dans ce cas un visage. \n",
    "Elle cr√©e une fen√™tre qui va se d√©placer dans l'image jusqu'√† ce qu'elle trouve quelque chose qui ressemble √† un visage humain.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/ins.png\" width=\"400\" center/>\n",
    "\n",
    "La recherche se fait √† plusieurs √©chelles. La fen√™tre aura une taille minimale, pour rep√©rer les visages petits ou √©loign√©s. \n",
    "Et une taille maximale pour trouver √©galement les plus grands visages dans l'image.\n",
    "Cette m√©thode prend donc l' **image d'entr√©e** comme premier param√®tre, un **facteur d'√©chelle**, par lequel la fen√™tre de recherche est multipli√©e √† chaque √©tape, un **rapport d'√©tape**, dans lequel 1 repr√©sente une recherche exhaustive et est g√©n√©ralement lent. \n",
    "En fixant ce param√®tre √† des valeurs plus √©lev√©es, les r√©sultats seront moins bons mais le calcul sera beaucoup plus rapide. \n",
    "Habituellement, des valeurs comprises entre 1 et 1,5 donnent de bons r√©sultats. \n",
    "Ensuite, les **taille minimale et maximale de la fen√™tre** sont d√©finies. \n",
    "Elles sp√©cifient l'intervalle des fen√™tres de recherche qui sont appliqu√©es √† l'image d'entr√©e pour d√©tecter les visages.\n",
    "\n",
    "```python\n",
    "detected = detector.detect_multi_scale(img=image, \n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "```\n",
    "\n",
    "## üìå Visages d√©tect√©s  \n",
    "\n",
    "```python\n",
    "print(detected)\n",
    "# Affichage de l'image avec le visage d√©tect√© identifi√©\n",
    "show_detected_face(image, detected)\n",
    "```\n",
    "<code>Detected face: [{'r': 115, 'c': 210, 'width': 167, 'height': 167}]</code>\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/ins_detect.png\" width=\"400\" center/>\n",
    "\n",
    "#### Affichage des visages d√©tect√©s\n",
    "Avec cette fonction, on trace un rectangle autour des faces d√©tect√©es. \n",
    "Nous ne discuterons pas de cette fonction en d√©tail ici.\n",
    "\n",
    "```python\n",
    "def show_detected_face(result, detected, title=\"Image du visage\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for patch in detected:\n",
    "        \n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2)\n",
    "        )\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìùIl y a quelqu'un ?\n",
    "Dans cet exercice, vous allez v√©rifier si une personne est pr√©sente ou non dans une image prise la nuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def crop_face(result, detected, title=\"Visage d√©tect√©\"):\n",
    "    for d in detected:\n",
    "        print(d)\n",
    "        rostro= result[d['r']:d['r']+d['width'], d['c']:d['c']+d['height']]\n",
    "    \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(rostro)    \n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def show_detected_face(result, detected, title=\"Image du visage\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for patch in detected:\n",
    "        \n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2)\n",
    "        )\n",
    "    plt.show()\n",
    "    crop_face(result, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.feature import Cascade\n",
    "\n",
    "night_image = imread('data/CM_SampleImages/Chapter4/face_det3.jpg')\n",
    "\n",
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img=night_image, scale_factor=1.2,\n",
    "                                       step_ratio=1, min_size=(10, 10), max_size=(200, 200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìùVisages multiples\n",
    "Dans cet exercice, vous allez d√©tecter plusieurs visages dans une image et les afficher individuellement.\n",
    "Pensez-y comme un moyen de cr√©er un ensemble de donn√©es sur les visages de vos propres amis !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_image = imread('data/CM_SampleImages/Chapter4/face_det_friends.jpg')\n",
    "\n",
    "# D√©tecter les visages avec un facteur d'√©chelle de 1.2 et un rapport d'√©tape de 1.\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "\n",
    "# Afficher les visages d√©tect√©s\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìùSegmentation et d√©tection de visage\n",
    "Auparavant, vous avez appris √† rendre les processus plus efficaces en termes de calcul avec une segmentation superpixel non supervis√©e. Dans cet exercice, c'est exactement ce que vous ferez¬†!\n",
    "\n",
    "√Ä l'aide de la fonction <code>slic()</code> pour la segmentation, r√©aliser le pr√©-traitement de l'image avant de la transmettre au d√©tecteur de visage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "profile_image = imread('data/CM_SampleImages/Chapter4/face_det.jpg')\n",
    "\n",
    "# Obtention de la segmentation avec 100 r√©gions par d√©faut\n",
    "segments = slic(profile_image, start_label=1)\n",
    "\n",
    "# Obtention de l'image segment√©e en utilisant label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg', bg_label=0)\n",
    "\n",
    "# D√©tection des visages avec la m√©thode multi-√©chelle\n",
    "detected = detector.detect_multi_scale(img=segmented_image, scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(1000, 1000))\n",
    "\n",
    "# Affichage des visages d√©tect√©s\n",
    "show_detected_face(segmented_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# üìïApplications dans le monde r√©el\n",
    "Nous allons maintenant apprendre √† appliquer ce que nous avons appris dans des situations du \"real-world\". Pour ce faire, nous allons combiner des techniques.\n",
    "\n",
    "## üìå Applications\n",
    "- Passage en niveaux de gris avant la d√©tection des bords/coins\n",
    "- R√©duction du bruit et restauration des images\n",
    "- D√©tection de visages flous\n",
    "- Approximation de la taille des objets\n",
    "\n",
    "## üìå Protection de la vie priv√©e\n",
    "Voyons comment r√©soudre un cas de protection de la vie priv√©e en d√©tectant les visages, puis en les rendant anonymes. Nous allons utiliser cette image pour travailler.\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/friends.png\" width=\"450\" center/>\n",
    "\n",
    "Donc, pour ce cas en particulier, nous devrons d'abord d√©tecter les visages, en utilisant le d√©tecteur de cascade de classificateurs, puis appliquer un filtre gaussien aux visages recadr√©s.\n",
    "```python\n",
    "# Importation du d√©tecteur de cascade de classifieurs et un filtre gaussien\n",
    "from skimage.feature import Cascade\n",
    "from skimage.filters import gaussian\n",
    "```\n",
    "<br/>\n",
    "Ainsi, avec le d√©tecteur de visage initialis√© et pr√™t √† l'emploi, nous pouvons commencer √† d√©tecter les visages. Pour chaque visage d√©tect√©, comme la variable d, dans la liste d√©tect√©e, nous allons utiliser les coordonn√©es pour le recadrer de l'image, c'est-√†-dire l'extraire.\n",
    "\n",
    "```python\n",
    "# D√©tection des visages\n",
    "detected = detector.detect_multi_scale(img=image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(50, 50),\n",
    "                                       max_size=(100, 100))\n",
    "# Pour chaque visage d√©tect√©\n",
    "for d in detected:\n",
    "    # Obtention du visage recadr√© √† partir des coordonn√©es d√©tect√©es\n",
    "    face = getFace(d)\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Cette fonction <code>getFace()</code> d√©coupe le visage de l'image, en utilisant le dictionnaire des visages d√©tect√©s qui contient les coordonn√©es. \n",
    "Ensuite, nous allons dessiner un rectangle autour du visage d√©tect√© de l'image. \n",
    "En prenant r, qui est la position de la ligne du coin sup√©rieur gauche du rectangle d√©tect√© comme position de d√©part X et c, qui est la colonne comme position de d√©part Y.\n",
    "\n",
    "```python\n",
    "def getFace(d):\n",
    "    # Extraction du rectangle du visage de l'image en utilisant les coordonn√©es du visage d√©tect√©.\n",
    "   \n",
    "    # X et Y points de d√©part du rectangle du visage\n",
    "    x, y = d['r'], d['c']\n",
    "    \n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "    \n",
    "    # Extraction du visage d√©tect√©\n",
    "    face= image[x:width, y:height]\n",
    "    \n",
    "    return face\n",
    "```\n",
    "\n",
    "Ce sont les points √† partir desquels nous allons maintenant ajouter une largeur et une hauteur pour compl√©ter le rectangle. Et c'est exactement ce que nous faisons ensuite, nous ajoutons la hauteur et la largeur aux points de d√©part. Nous avons donc les dimensions du rectangle dans l'image. Nous sp√©cifions ensuite ces dimensions dans l'image d'origine √† partir de laquelle le visage a √©t√© d√©tect√© afin de pouvoir le recadrer.\n",
    "\n",
    "<br/>\n",
    "Maintenant que le visage est recadr√© de l'image, nous allons appliquer le filtre gaussien pour le rendre flou et le rendre m√©connaissable. Cette\n",
    "l'image r√©sultante est affect√©e √† la variable gaussian_face.\n",
    "\n",
    "```python\n",
    "# D√©tection des visages\n",
    "detected = detector.detect_multi_scale(img=image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(50, 50),\n",
    "                                       max_size=(100, 100))\n",
    "# Pour chaque visage d√©tect√©\n",
    "for d in detected:\n",
    "    # Obtention du visage isol√© √† partir des coordonn√©es obtenues\n",
    "    face = getFace(d)\n",
    "    \n",
    "    # Application d'un filtre gaussien sur les visages obtenus\n",
    "    gaussian_face = gaussian(face, multichannel=True, sigma = 10)\n",
    "    \n",
    "    # Fusion de ce visage flou avec notre image finale et affichage final\n",
    "    resulting_image = mergeBlurryFace(image, gaussian_face)\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Comme derni√®re √©tape, nous allons fusionner le visage flou √† nouveau √† l'image, en utilisant une autre fonction appel√©e <code>mergeBlurryFace()</code> Pour ce faire, nous sp√©cifions √† nouveau les points de d√©part X et Y ainsi que la largeur et la hauteur, afin de d√©couper l'image originale. Ensuite, le visage flou est affect√© au r√©sultat.\n",
    "\n",
    "```python\n",
    "def mergeBlurryFace(original, gaussian_image):\n",
    "    # Les points de d√©part X et Y du rectangle du visage.\n",
    "    x, y = d['r'], d['c'] \n",
    "    # La largeur et la hauteur du rectangle de la face\n",
    "    width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "    \n",
    "    original[ x:width, y:height] = gaussian_image\n",
    "    return original\n",
    "```\n",
    "\n",
    "<img src=\"data/CM_SampleImages/Chapter4/blurr_faces.png\" width=\"450\" center/>\n",
    "\n",
    "Il en r√©sulte donc une image qui ne contient plus les visages des personnes et, de cette mani√®re, les donn√©es personnelles sont anonymis√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "##  üìù Protection de la vie priv√©e\n",
    "Prenons une application r√©elle de ce que vous avez appris dans ce cours.\n",
    "\n",
    "Dans cet exercice, vous allez d√©tecter des visages humains dans l'image et, au nom de la protection de la vie priv√©e, vous allez anonymiser les donn√©es en floutant automatiquement les visages des personnes dans l'image.\n",
    "\n",
    "Vous pouvez utiliser le filtre gaussien pour le flou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceRectangle(image, d):\n",
    "    ''' Extraction du visage √† partir de l'image en utilisant les coordonn√©es de l'image d√©tect√©e. '''\n",
    "    # Points de d√©part X et Y du rectangle de la face\n",
    "    x, y  = d['r'], d['c']\n",
    "    \n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']\n",
    "    \n",
    "    # Extraction du visage d√©tect√©\n",
    "    face= image[ x:width, y:height]\n",
    "    return face\n",
    "\n",
    "def mergeBlurryFace(original, gaussian_image):\n",
    "     # Points de d√©part X et Y du rectangle du visage\n",
    "    x, y  = d['r'], d['c']\n",
    "    # La largeur et la hauteur du rectangle du visage\n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']\n",
    "    \n",
    "    original[ x:width, y:height] = gaussian_image\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "group_image = imread('data/CM_SampleImages/Chapter4/face_det25.jpg')\n",
    "\n",
    "# D√©tection des visages\n",
    "detected = detector.detect_multi_scale(img=group_image, scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10), max_size=(100, 100))\n",
    "\n",
    "# Pour chaque visage d√©tect√©\n",
    "for d in detected:\n",
    "    # Obtention du rectangle du visage √† partir des coordonn√©es d√©tect√©es\n",
    "    face = getFaceRectangle(group_image, d)\n",
    "    \n",
    "    # Application du filtre gaussien au visage extrait\n",
    "    blurred_face = gaussian(face, channel_axis=-1, sigma=8, preserve_range=True)\n",
    "    \n",
    "    # Fusion de ce visage flou √† notre image finale et affichage\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face)\n",
    "    \n",
    "show_image(resulting_image, 'Blurred faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "##  üìù Aidez Sally √† restaurer sa photo de fin d'√©tudes\n",
    "Vous allez combiner toutes les connaissances que vous avez acquises tout au long du cours pour relever un dernier d√©fi : reconstruire une photo tr√®s endommag√©e.\n",
    "\n",
    "Aidez Sally √† restaurer son portrait pr√©f√©r√© qui a √©t√© endommag√© par du bruit, de la distorsion et des informations manquantes en raison d'une br√®che dans son ordinateur portable.\n",
    "\n",
    "Vous allez r√©soudre les probl√®mes de cette image en :\n",
    "\n",
    "- La faisant pivoter pour qu'elle soit droite en utilisant rotate()\n",
    "- Appliquant une r√©duction du bruit avec denoise_tv_chambolle()\n",
    "- Reconstruisant les parties endommag√©es avec inpaint_biharmonic() du module inpaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(image):\n",
    "    # Cr√©ation d'un masque avec trois r√©gions de d√©fauts : gauche, milieu, droite respectivement.\n",
    "    mask_for_solution = np.zeros(image.shape[:-1])\n",
    "    mask_for_solution[450:475, 470:495] = 1\n",
    "    mask_for_solution[320:355, 140:175] = 1\n",
    "    mask_for_solution[130:155, 345:370] = 1\n",
    "    return mask_for_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "damaged_image = imread('data/CM_SampleImages/Chapter4/sally_damaged_image.jpg')\n",
    "\n",
    "# Transformation de l'image pour qu'elle ne soit pas en rotation\n",
    "upright_img = transform.rotate(damaged_image, 20)\n",
    "\n",
    "# √âlimination du bruit de l'image, en utilisant la m√©thode de Chambolle\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img, weight=0.1, channel_axis=-1)\n",
    "\n",
    "# Reconstruction des parties manquantes de l'image\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, channel_axis=-1)\n",
    "\n",
    "# Affichage de l'image r√©sultante\n",
    "plot_comparison(damaged_image, result, \"Reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
